#! /bin/zsh
#conda activate ddd
nohup python -u ./src/main_run.py --datadir='./dataset/Wiki10-31K/' --istrain=0 --is_pred_trn=0 --is_pred_tst=0 --iscombine=0 --is_rank_train=0 --is_ranking=1 --combine_model='bi-encoder' --modelname='t5-large' --outputmodel='t5l_save' --batch_size=2 --epoch=5 --checkdir='t5l_check' --data_size=6 --combine_model='bi-encoder' --rank_model='all-MiniLM-L6-v2' --rank_batch=128 --rankmodel_save='bi_en'>> ./log/output.log 2>&1 &